{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seahorse_LSTM1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W69sW5ZHFgjM",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.signal\n",
        "from sys import getsizeof\n",
        "import matplotlib.pyplot as plt\n",
        "import re \n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMGbfyNVHNea",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dense, LSTM, Dropout, Flatten, Activation, Conv1D, MaxPooling1D, Masking, Reshape\n",
        "from keras.layers import BatchNormalization, concatenate, Permute, GlobalAveragePooling1D, multiply\n",
        "from keras.models import Sequential, Model\n",
        "from keras import optimizers\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpmsBvm1TzTa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "53945c52-0454-4193-ae41-f19f2a866e3c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crP2mwhHTaWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = 'gdrive/My Drive/ColabNotebooks/Seahorse/buy/' \n",
        "n_bar = 41"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xfqxvP7TaWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_data(data): \n",
        "    for i in range(data.shape[0]): \n",
        "        row = data.iloc[i, :] \n",
        "        data.iloc[i, :] = (row - min(row))/(max(row) - min(row)) \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reQlrTz7TaWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    \n",
        "    data = pd.DataFrame()\n",
        "    \n",
        "    for filename in os.listdir(file_path):\n",
        "        if filename.endswith(\".txt\"): \n",
        "            tmp_df = pd.read_csv(os.path.join(file_path, filename), delimiter= '\\s+', header = None)\n",
        "            tmp_df = tmp_df.astype(float)\n",
        "            tmp_df = tmp_df.iloc[10:,:]\n",
        "            data = pd.concat([data, tmp_df])\n",
        "    \n",
        "    # remove duplicate data entries \n",
        "    origin_len = data.shape[0]\n",
        "    data = data.drop_duplicates()\n",
        "    print('{} duplicate data entries removed.'.format(origin_len - data.shape[0]))\n",
        "    \n",
        "    # remove data entries whose stock prices are lower than 5.0\n",
        "    origin_len = data.shape[0]\n",
        "    data = data[data[n_bar] >= 5.0]\n",
        "    print('{} low stock price data entries removed.'.format(origin_len - data.shape[0]))\n",
        "    \n",
        "    # remove data entries with extreme oscillator values \n",
        "    origin_len = data.shape[0]\n",
        "    data = data[(data[0] > -7) & (data[0] < 7)] \n",
        "    print('{} extreme oscillator values  removed.'.format(origin_len - data.shape[0]))\n",
        "    \n",
        "    '''\n",
        "    # remove data entries with near-zero oscillator values \n",
        "    origin_len = data.shape[0]\n",
        "    data = data[(data[0] < -0.5) | (data[0] > 0.5)] \n",
        "    print('{} near-zero oscillator values  removed.'.format(origin_len - data.shape[0]))\n",
        "    '''\n",
        "    \n",
        "    # remove data entries with extreme return values\n",
        "    origin_len = data.shape[0]\n",
        "    data = data[(data[n_bar*3] > -50) & (data[n_bar*3] < 50)]\n",
        "    print('{} extreme return values removed.'.format(origin_len - data.shape[0]))\n",
        "    \n",
        "    # balance the data set\n",
        "    origin_len = data.shape[0]\n",
        "    pos = data[data[n_bar*3] > 0]\n",
        "    neg = data[data[n_bar*3] <= 0]\n",
        "    if pos.shape[0] > neg.shape[0]:\n",
        "      pos = pos.sample(neg.shape[0])\n",
        "    elif pos.shape[0] < neg.shape[0]:\n",
        "      neg = neg.sample(pos.shape[0])\n",
        "    data = pd.concat([pos, neg], axis=0)\n",
        "    print('balancing removed {} rows.'.format(origin_len - data.shape[0]))\n",
        "    \n",
        "    data = data.reset_index(drop=True)\n",
        "    \n",
        "    # set column names\n",
        "    osc_names = ['osc' + str(i) for i in range(n_bar)]\n",
        "    prc_names = ['prc' + str(i) for i in range(n_bar)]\n",
        "    macd_names = ['macd' + str(i) for i in range(n_bar)]\n",
        "    data.columns = osc_names + prc_names + macd_names + ['rtn']\n",
        "    \n",
        "    osc_data = data.iloc[:, :n_bar]\n",
        "    osc_data = osc_data[osc_data.columns[::-1]]\n",
        "    osc_data = normalize_data(osc_data)    # normalize oscillator data \n",
        "    \n",
        "    prc_data = data.iloc[:, n_bar:n_bar*2]\n",
        "    prc_data = prc_data[prc_data.columns[::-1]]\n",
        "    prc_data = normalize_data(prc_data)    # normalize price data\n",
        "    \n",
        "    macd_data = data.iloc[:, n_bar*2:n_bar*3]\n",
        "    macd_data = macd_data[macd_data.columns[::-1]]\n",
        "    macd_data = normalize_data(macd_data)    # normalize macd data \n",
        "    \n",
        "    rtn = data['rtn']\n",
        "    label = pd.Series(map(lambda x: 1 if x>0 else 0, rtn), name = 'label')\n",
        "    \n",
        "    return osc_data, prc_data, macd_data, rtn, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAZchrFaTaWh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "75cd6abe-771e-4ab9-d2bb-855588cdaa5e"
      },
      "source": [
        "osc_data, prc_data, macd_data, rtn, label = load_data()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "735 duplicate data entries removed.\n",
            "5167 low stock price data entries removed.\n",
            "740 extreme oscillator values  removed.\n",
            "34438 near-zero oscillator values  removed.\n",
            "2 extreme return values removed.\n",
            "balancing removed 10477 rows.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk_LXnh1TaWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4b713da7-4cab-4e98-b025-1c9d5fbea7bd"
      },
      "source": [
        "osc_data.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51332, 41)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaIo_s68TaWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "77aad79f-11b5-4d93-b0d6-fe311804b764"
      },
      "source": [
        "X = pd.concat([osc_data, prc_data, macd_data], axis=1)\n",
        "y = label\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25) \n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38499, 123)\n",
            "(38499,)\n",
            "(12833, 123)\n",
            "(12833,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_seI5BKYwdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1fad2057-c531-425e-806b-7290ffb85852"
      },
      "source": [
        "# balance training set\n",
        "tmp = pd.concat([X_train, y_train], axis=1)\n",
        "tmp_pos = tmp[tmp['label'] == 1]\n",
        "tmp_neg = tmp[tmp['label'] == 0]\n",
        "print('originally there are {} positive signals and {} negative signals in the training set.'.format(tmp_pos.shape[0], tmp_neg.shape[0]))\n",
        "\n",
        "if tmp_pos.shape[0] > tmp_neg.shape[0]: \n",
        "  tmp_pos = tmp_pos.sample(tmp_neg.shape[0])\n",
        "elif tmp_pos.shape[0] < tmp_neg.shape[0]:\n",
        "  tmp_neg = tmp_neg.sample(tmp_pos.shape[0])\n",
        "\n",
        "  tmp = pd.concat([tmp_pos, tmp_neg], axis = 0)\n",
        "y_train = tmp['label']\n",
        "X_train = tmp.drop(['label'], axis = 1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "originally there are 19263 positive signals and 27093 negative signals in the training set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd0mvYnJTaXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "552b627f-2f02-44ca-f987-385b5c0299f9"
      },
      "source": [
        "# check how balanced are the balanced data sets\n",
        "print(sum(y_train)/y_train.shape[0])\n",
        "print(sum(y_test)/y_test.shape[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.49853242941375103\n",
            "0.504402711758747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-Tez_0gVpuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train).reshape(X_train.shape[0], 3, 41)\n",
        "y_train = to_categorical(y_train)\n",
        "X_test = np.array(X_test).reshape(X_test.shape[0], 3, 41)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjLV4fgmj033",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.transpose(X_train, (0, 2, 1))\n",
        "X_test = np.transpose(X_test, (0, 2, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60gctusbl9IV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d54aab8b-b010-4636-f254-2450eebdd080"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38499, 41, 3)\n",
            "(38499, 2)\n",
            "(12833, 41, 3)\n",
            "(12833, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeT23JE8jkZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this function is copied from https://github.com/titu1994/MLSTM-FCN/blob/master/ozone_model.py \n",
        "\n",
        "def squeeze_excite_block(input):\n",
        "    filters = input._keras_shape[-1]    # channel_axis = -1 for TF\n",
        "\n",
        "    se = GlobalAveragePooling1D()(input)\n",
        "    se = Reshape((1, filters))(se)\n",
        "    se = Dense(filters // 16,  activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = multiply([input, se])\n",
        "    return se"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTpJSFSwTaW0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4ff4d4eb-d055-46af-f89d-f8cb2a961f56"
      },
      "source": [
        "ip = Input(shape=(n_bar, 3))\n",
        "\n",
        "lstm = Masking()(ip)\n",
        "lstm = LSTM(8)(ip) \n",
        "lstm = Dropout(rate=0.2)(lstm) \n",
        "\n",
        "cnn = Permute((2, 1))(ip)\n",
        "cnn = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(cnn)\n",
        "cnn = BatchNormalization()(cnn)\n",
        "cnn = Activation('relu')(cnn)\n",
        "cnn = squeeze_excite_block(cnn)\n",
        "\n",
        "cnn = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(cnn) \n",
        "cnn = BatchNormalization()(cnn)\n",
        "cnn = Activation('relu')(cnn)\n",
        "cnn = squeeze_excite_block(cnn)\n",
        "\n",
        "cnn = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(cnn)\n",
        "cnn = BatchNormalization()(cnn)\n",
        "cnn = Activation('relu')(cnn)\n",
        "\n",
        "cnn = GlobalAveragePooling1D()(cnn) \n",
        "\n",
        "lstm_cnn = concatenate([lstm, cnn])\n",
        "\n",
        "op = Dense(2, activation='softmax')(lstm_cnn)\n",
        "\n",
        "model = Model(ip, op)\n",
        "model.summary"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Network.summary of <keras.engine.training.Model object at 0x7fdebab1a400>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXJzhP4bTaW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1706
        },
        "outputId": "11e25b65-74aa-4fa6-8480-0a43e8ce69a5"
      },
      "source": [
        "optm = optimizers.Adam(lr=1e-3)\n",
        "model.compile(optimizer=optm, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, batch_size=128, epochs=50, verbose=2, validation_data=(X_test, y_test))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 38499 samples, validate on 12833 samples\n",
            "Epoch 1/50\n",
            " - 24s - loss: 0.7033 - acc: 0.5038 - val_loss: 0.6971 - val_acc: 0.4985\n",
            "Epoch 2/50\n",
            " - 21s - loss: 0.6948 - acc: 0.5054 - val_loss: 0.6946 - val_acc: 0.5097\n",
            "Epoch 3/50\n",
            " - 21s - loss: 0.6939 - acc: 0.5112 - val_loss: 0.6931 - val_acc: 0.5102\n",
            "Epoch 4/50\n",
            " - 21s - loss: 0.6936 - acc: 0.5142 - val_loss: 0.6944 - val_acc: 0.5142\n",
            "Epoch 5/50\n",
            " - 21s - loss: 0.6938 - acc: 0.5140 - val_loss: 0.6945 - val_acc: 0.5106\n",
            "Epoch 6/50\n",
            " - 21s - loss: 0.6933 - acc: 0.5172 - val_loss: 0.7062 - val_acc: 0.4956\n",
            "Epoch 7/50\n",
            " - 21s - loss: 0.6933 - acc: 0.5162 - val_loss: 0.6939 - val_acc: 0.5081\n",
            "Epoch 8/50\n",
            " - 21s - loss: 0.6930 - acc: 0.5197 - val_loss: 0.6963 - val_acc: 0.5101\n",
            "Epoch 9/50\n",
            " - 21s - loss: 0.6926 - acc: 0.5151 - val_loss: 0.6939 - val_acc: 0.5162\n",
            "Epoch 10/50\n",
            " - 21s - loss: 0.6920 - acc: 0.5218 - val_loss: 0.7085 - val_acc: 0.4949\n",
            "Epoch 11/50\n",
            " - 21s - loss: 0.6916 - acc: 0.5243 - val_loss: 0.6972 - val_acc: 0.4989\n",
            "Epoch 12/50\n",
            " - 21s - loss: 0.6923 - acc: 0.5230 - val_loss: 0.6955 - val_acc: 0.5109\n",
            "Epoch 13/50\n",
            " - 21s - loss: 0.6916 - acc: 0.5243 - val_loss: 0.6957 - val_acc: 0.5097\n",
            "Epoch 14/50\n",
            " - 21s - loss: 0.6910 - acc: 0.5276 - val_loss: 0.6948 - val_acc: 0.5095\n",
            "Epoch 15/50\n",
            " - 21s - loss: 0.6912 - acc: 0.5294 - val_loss: 0.6934 - val_acc: 0.5116\n",
            "Epoch 16/50\n",
            " - 21s - loss: 0.6902 - acc: 0.5290 - val_loss: 0.6953 - val_acc: 0.5021\n",
            "Epoch 17/50\n",
            " - 21s - loss: 0.6899 - acc: 0.5324 - val_loss: 0.6972 - val_acc: 0.5090\n",
            "Epoch 18/50\n",
            " - 21s - loss: 0.6898 - acc: 0.5353 - val_loss: 0.6948 - val_acc: 0.5148\n",
            "Epoch 19/50\n",
            " - 21s - loss: 0.6891 - acc: 0.5376 - val_loss: 0.6987 - val_acc: 0.5057\n",
            "Epoch 20/50\n",
            " - 21s - loss: 0.6890 - acc: 0.5385 - val_loss: 0.7055 - val_acc: 0.5040\n",
            "Epoch 21/50\n",
            " - 21s - loss: 0.6879 - acc: 0.5414 - val_loss: 0.7048 - val_acc: 0.5021\n",
            "Epoch 22/50\n",
            " - 21s - loss: 0.6876 - acc: 0.5427 - val_loss: 0.7001 - val_acc: 0.5021\n",
            "Epoch 23/50\n",
            " - 21s - loss: 0.6871 - acc: 0.5414 - val_loss: 0.7053 - val_acc: 0.5044\n",
            "Epoch 24/50\n",
            " - 20s - loss: 0.6861 - acc: 0.5457 - val_loss: 0.7005 - val_acc: 0.5055\n",
            "Epoch 25/50\n",
            " - 21s - loss: 0.6855 - acc: 0.5462 - val_loss: 0.7024 - val_acc: 0.5064\n",
            "Epoch 26/50\n",
            " - 21s - loss: 0.6854 - acc: 0.5469 - val_loss: 0.7036 - val_acc: 0.5050\n",
            "Epoch 27/50\n",
            " - 20s - loss: 0.6839 - acc: 0.5527 - val_loss: 0.7012 - val_acc: 0.5067\n",
            "Epoch 28/50\n",
            " - 21s - loss: 0.6826 - acc: 0.5554 - val_loss: 0.7025 - val_acc: 0.5113\n",
            "Epoch 29/50\n",
            " - 21s - loss: 0.6815 - acc: 0.5580 - val_loss: 0.7078 - val_acc: 0.5064\n",
            "Epoch 30/50\n",
            " - 21s - loss: 0.6805 - acc: 0.5592 - val_loss: 0.7003 - val_acc: 0.5105\n",
            "Epoch 31/50\n",
            " - 21s - loss: 0.6792 - acc: 0.5631 - val_loss: 0.7049 - val_acc: 0.5101\n",
            "Epoch 32/50\n",
            " - 20s - loss: 0.6779 - acc: 0.5639 - val_loss: 0.7066 - val_acc: 0.5053\n",
            "Epoch 33/50\n",
            " - 21s - loss: 0.6760 - acc: 0.5711 - val_loss: 0.7124 - val_acc: 0.5063\n",
            "Epoch 34/50\n",
            " - 20s - loss: 0.6741 - acc: 0.5737 - val_loss: 0.7120 - val_acc: 0.5058\n",
            "Epoch 35/50\n",
            " - 20s - loss: 0.6718 - acc: 0.5765 - val_loss: 0.7350 - val_acc: 0.5011\n",
            "Epoch 36/50\n",
            " - 20s - loss: 0.6694 - acc: 0.5817 - val_loss: 0.7136 - val_acc: 0.5042\n",
            "Epoch 37/50\n",
            " - 21s - loss: 0.6669 - acc: 0.5861 - val_loss: 0.7167 - val_acc: 0.5050\n",
            "Epoch 38/50\n",
            " - 21s - loss: 0.6639 - acc: 0.5910 - val_loss: 0.7269 - val_acc: 0.5046\n",
            "Epoch 39/50\n",
            " - 20s - loss: 0.6608 - acc: 0.5952 - val_loss: 0.7239 - val_acc: 0.5039\n",
            "Epoch 40/50\n",
            " - 20s - loss: 0.6578 - acc: 0.6017 - val_loss: 0.7479 - val_acc: 0.5060\n",
            "Epoch 41/50\n",
            " - 21s - loss: 0.6535 - acc: 0.6073 - val_loss: 0.7330 - val_acc: 0.5038\n",
            "Epoch 42/50\n",
            " - 20s - loss: 0.6491 - acc: 0.6140 - val_loss: 0.7361 - val_acc: 0.5049\n",
            "Epoch 43/50\n",
            " - 20s - loss: 0.6447 - acc: 0.6142 - val_loss: 0.7443 - val_acc: 0.5004\n",
            "Epoch 44/50\n",
            " - 21s - loss: 0.6386 - acc: 0.6220 - val_loss: 0.7706 - val_acc: 0.5029\n",
            "Epoch 45/50\n",
            " - 21s - loss: 0.6344 - acc: 0.6275 - val_loss: 0.7783 - val_acc: 0.4989\n",
            "Epoch 46/50\n",
            " - 20s - loss: 0.6289 - acc: 0.6316 - val_loss: 0.7563 - val_acc: 0.5006\n",
            "Epoch 47/50\n",
            " - 20s - loss: 0.6225 - acc: 0.6393 - val_loss: 0.7780 - val_acc: 0.5044\n",
            "Epoch 48/50\n",
            " - 20s - loss: 0.6156 - acc: 0.6512 - val_loss: 0.7658 - val_acc: 0.5021\n",
            "Epoch 49/50\n",
            " - 21s - loss: 0.6096 - acc: 0.6521 - val_loss: 0.7703 - val_acc: 0.5031\n",
            "Epoch 50/50\n",
            " - 20s - loss: 0.6016 - acc: 0.6611 - val_loss: 0.7918 - val_acc: 0.5015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLWllcxXTaX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "e2077eea-f9f8-47f5-a30d-1873ff561aa6"
      },
      "source": [
        "# results using training set and valid set \n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.hlines(0.5, 0, 50, linestyles='dotted')\n",
        "plt.ylim(0.45, 0.70)\n",
        "plt.xticks(range(0, 50))\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['train', 'valid']);"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXeaWXyBAxQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TGtoOZsaKWNV",
        "outputId": "497c78bb-6383-40fb-a1ad-baff85fff825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(model.evaluate(X_test, y_test, verbose=1))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12833/12833 [==============================] - 2s 124us/step\n",
            "[0.7347037167316158, 0.5051819527779943]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nz--fTpdgeuU",
        "colab": {}
      },
      "source": [
        "pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE3GrXJ4r8pq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "47548ec7-d8da-43b5-f30c-00d06c0f1d49"
      },
      "source": [
        "pred[:10, :]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.23070341, 0.7692965 ],\n",
              "       [0.76599735, 0.23400263],\n",
              "       [0.15451215, 0.84548783],\n",
              "       [0.65897965, 0.34102032],\n",
              "       [0.43953037, 0.5604696 ],\n",
              "       [0.28754872, 0.7124513 ],\n",
              "       [0.63702834, 0.36297172],\n",
              "       [0.32686573, 0.67313427],\n",
              "       [0.9607487 , 0.03925136],\n",
              "       [0.604691  , 0.395309  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L4xrWHxTicLp",
        "colab": {}
      },
      "source": [
        "# pred_probs = pd.Series(pred[:, 1], name = \"pred_probs\")\n",
        "\n",
        "results = pd.concat([pd.Series(pred[:, 1], name = \"pred_probs\"), pd.Series(y_test[:, 1], name='label')], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vyFrWzT_l7R_",
        "colab": {}
      },
      "source": [
        "results['pred_prob_level'] = [int(x * 20)/20 for x in results['pred_probs']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CKoZ2gtQlU0m",
        "outputId": "e2fb0ce3-31de-410b-b029-addd01bc683a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        }
      },
      "source": [
        "summary = pd.concat([results.groupby(['pred_prob_level']).mean(), \n",
        "                     results.groupby(['pred_prob_level']).count()['label'], \n",
        "                     100 * results.groupby(['pred_prob_level']).count()['label']/results.shape[0]], \n",
        "                    axis = 1)\n",
        "summary.columns = ['predicted win prob', 'actual win rate', '# of trades', '% of all trades']\n",
        "summary"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted win prob</th>\n",
              "      <th>actual win rate</th>\n",
              "      <th># of trades</th>\n",
              "      <th>% of all trades</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_prob_level</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.00</th>\n",
              "      <td>0.030699</td>\n",
              "      <td>0.438776</td>\n",
              "      <td>98</td>\n",
              "      <td>0.763656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.05</th>\n",
              "      <td>0.077011</td>\n",
              "      <td>0.532051</td>\n",
              "      <td>156</td>\n",
              "      <td>1.215616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.10</th>\n",
              "      <td>0.126056</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>207</td>\n",
              "      <td>1.613029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.15</th>\n",
              "      <td>0.176061</td>\n",
              "      <td>0.484642</td>\n",
              "      <td>293</td>\n",
              "      <td>2.283176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.20</th>\n",
              "      <td>0.225739</td>\n",
              "      <td>0.503704</td>\n",
              "      <td>405</td>\n",
              "      <td>3.155926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.25</th>\n",
              "      <td>0.276661</td>\n",
              "      <td>0.517578</td>\n",
              "      <td>512</td>\n",
              "      <td>3.989714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.30</th>\n",
              "      <td>0.326478</td>\n",
              "      <td>0.506438</td>\n",
              "      <td>699</td>\n",
              "      <td>5.446895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.35</th>\n",
              "      <td>0.375568</td>\n",
              "      <td>0.497712</td>\n",
              "      <td>874</td>\n",
              "      <td>6.810567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.40</th>\n",
              "      <td>0.425807</td>\n",
              "      <td>0.498513</td>\n",
              "      <td>1009</td>\n",
              "      <td>7.862542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.45</th>\n",
              "      <td>0.475574</td>\n",
              "      <td>0.506791</td>\n",
              "      <td>1178</td>\n",
              "      <td>9.179459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.50</th>\n",
              "      <td>0.525402</td>\n",
              "      <td>0.508719</td>\n",
              "      <td>1319</td>\n",
              "      <td>10.278189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.55</th>\n",
              "      <td>0.574223</td>\n",
              "      <td>0.506033</td>\n",
              "      <td>1326</td>\n",
              "      <td>10.332736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.60</th>\n",
              "      <td>0.625123</td>\n",
              "      <td>0.493711</td>\n",
              "      <td>1272</td>\n",
              "      <td>9.911946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.65</th>\n",
              "      <td>0.673675</td>\n",
              "      <td>0.518583</td>\n",
              "      <td>1157</td>\n",
              "      <td>9.015819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.70</th>\n",
              "      <td>0.723617</td>\n",
              "      <td>0.507312</td>\n",
              "      <td>889</td>\n",
              "      <td>6.927453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.75</th>\n",
              "      <td>0.773282</td>\n",
              "      <td>0.487521</td>\n",
              "      <td>601</td>\n",
              "      <td>4.683239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.80</th>\n",
              "      <td>0.823781</td>\n",
              "      <td>0.512755</td>\n",
              "      <td>392</td>\n",
              "      <td>3.054625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.85</th>\n",
              "      <td>0.874372</td>\n",
              "      <td>0.491736</td>\n",
              "      <td>242</td>\n",
              "      <td>1.885763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.90</th>\n",
              "      <td>0.923413</td>\n",
              "      <td>0.516340</td>\n",
              "      <td>153</td>\n",
              "      <td>1.192239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.95</th>\n",
              "      <td>0.964256</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>51</td>\n",
              "      <td>0.397413</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 predicted win prob  ...  % of all trades\n",
              "pred_prob_level                      ...                 \n",
              "0.00                       0.030699  ...         0.763656\n",
              "0.05                       0.077011  ...         1.215616\n",
              "0.10                       0.126056  ...         1.613029\n",
              "0.15                       0.176061  ...         2.283176\n",
              "0.20                       0.225739  ...         3.155926\n",
              "0.25                       0.276661  ...         3.989714\n",
              "0.30                       0.326478  ...         5.446895\n",
              "0.35                       0.375568  ...         6.810567\n",
              "0.40                       0.425807  ...         7.862542\n",
              "0.45                       0.475574  ...         9.179459\n",
              "0.50                       0.525402  ...        10.278189\n",
              "0.55                       0.574223  ...        10.332736\n",
              "0.60                       0.625123  ...         9.911946\n",
              "0.65                       0.673675  ...         9.015819\n",
              "0.70                       0.723617  ...         6.927453\n",
              "0.75                       0.773282  ...         4.683239\n",
              "0.80                       0.823781  ...         3.054625\n",
              "0.85                       0.874372  ...         1.885763\n",
              "0.90                       0.923413  ...         1.192239\n",
              "0.95                       0.964256  ...         0.397413\n",
              "\n",
              "[20 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gVMgwIxat-_L",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}